# %%
# Import libraries with respect to loading data and creating a random forest model
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt
import seaborn as sns

# %%
# Load the data from a csv file, and the name of the file is diabetes.csv
data = pd.read_csv('diabetes.csv')

# %%
# Mathematical operations on the dataset, like generating the birth year from age
data['BirthYear'] = 2020 - data['Age']

# %%
# Show the new column
data.head

# %%
# convert the BMI column to two decimal values
data['BMI'] = data['BMI'].apply(lambda x: round(x, 2))

# %%
# Show the new column only
data['BMI'].head()



# %%
# Perform count, min, max, std, mean, 25%, 50%, and 75% on the dataset
data.describe()

# %%
from sklearn.model_selection import train_test_split
# Split the data into training and testing data and the column name Diabetic is the target column
X = data.drop('Diabetic', axis=1)
y = data['Diabetic']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


# %%
# Perform univariate analysis on the dataset and plot the graphs
data.hist(figsize=(20, 20))
plt.show()


# %%
import matplotlib.pyplot as plt
import seaborn as sns
# Perform scatter plot on the dataset and plot the graphs size 20, 20
plt.figure(figsize=(20, 20))
sns.pairplot(data)
plt.show()


# %%

# Perform JointGrid plot on the dataset and plot the graphs with white background
sns.set(style='whitegrid')
g = sns.JointGrid(data=data, x='Age', y='BMI')
g.plot_joint(sns.scatterplot)
g.plot_marginals(sns.histplot, kde=True)
plt.show()


# %%
# Perform comparison on all features of the dataset and plot the graphs in a single plot using heatmap
plt.figure(figsize=(20, 20))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.show()

# %%
# Perform standardization on the data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(data.drop('Diabetic', axis=1))
X_train = scaler.transform(data.drop('Diabetic', axis=1))
X_test = pd.DataFrame(X_train, columns=data.columns[:-1])
X_test.head()


# %%
# Create a random forest model with 100 trees, and the criterion is entropy
rf = RandomForestClassifier(n_estimators=100, criterion='entropy')
X_train = X_train[:7000]
y_train = y_train[:7000]
rf.fit(X_train, y_train)

# %%
# Calculate the accuracy of the model
y_pred = rf.predict(X_test)
y_test = y_test[:7000]
#y_train = y_train[:7000]
print('Accuracy:', accuracy_score(y_test, y_pred))


